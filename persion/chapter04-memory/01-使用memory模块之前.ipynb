{
 "cells": [
  {
   "cell_type": "code",
   "id": "85d8e5548c1f348e",
   "metadata": {},
   "source": [
    "from langchain_classic.chains.conversation.base import ConversationChain\n",
    "from langchain_classic.chains.llm import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#1、获取大模型\n",
    "chat_model = ChatTongyi()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f3e7fc39feae35b1",
   "metadata": {},
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "def chat_with_model(question):\n",
    "    # 2、提供提示词模版：ChatPromptTemplate\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"你是一个人工智能的助手\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ])\n",
    "\n",
    "    while True:\n",
    "        chain = prompt_template | chat_model\n",
    "        res = chain.invoke({\"question\": question})\n",
    "        print(f\"模型回复：{res.content}\")\n",
    "        user_input = input(\"你还有其他问题吗？（输入‘退出’时，结束会话）\")\n",
    "        if (user_input == \"退出\"):\n",
    "            break\n",
    "        prompt_template.append(AIMessage(content=res.content))\n",
    "        prompt_template.append(HumanMessage(content=user_input))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "chat_with_model(\"你好，很高兴认识你\")"
   ],
   "id": "8f43d8ddc6ae6895",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "history = InMemoryChatMessageHistory()\n",
    "\n",
    "# 2、添加相关的消息进行存储\n",
    "\n",
    "history.add_user_message(\"你好\")\n",
    "history.add_ai_message(\"很高兴认识你\")"
   ],
   "id": "e9daeecbb9e76d3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "#3、打印存储的消息\n",
    "print(history.messages)\n"
   ],
   "id": "c565a6e9111f0cd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "场景2:对接LLM",
   "id": "988d9f731043bdd1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "chat_model = ChatTongyi()"
   ],
   "id": "82f3676a16c55709",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "history = InMemoryChatMessageHistory()\n",
    "\n",
    "# 2、添加相关的消息进行存储\n",
    "\n",
    "history.add_user_message(\"你好\")\n",
    "history.add_ai_message(\"很高兴认识你\")\n",
    "history.add_user_message(\"帮我计算1+2*3=？\")\n",
    "print(history.messages)"
   ],
   "id": "361f43f3c2b4f0a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "res = chat_model.invoke(history.messages)\n",
    "print(res.content)"
   ],
   "id": "b98c9b95f5de51e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2、使用ConversationBufferMemory进行多轮对话\n",
    "举例1：以字符串的方式返回存储的信息"
   ],
   "id": "daadf4bad3e15f77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_classic.memory import ConversationBufferMemory\n",
    "\n",
    "# 1、ConversationBufferMemory的实例化\n",
    "memory = ConversationBufferMemory()\n",
    "#inputs对应用户的消息，outputs对应ai消息\n",
    "memory.save_context(inputs={\"input\": \"你好，我叫小明\"}, outputs={\"output\": \"很高兴认识你\"})\n",
    "memory.save_context(inputs={\"input\": \"帮我回答一下1+2*3=?\"}, outputs={\"output\": \"7\"})\n",
    "\n",
    "#3、获取存储到记忆中的信息\n",
    "print(memory.load_memory_variables({}))\n",
    "#返回的字典结构的key叫history"
   ],
   "id": "918a4db227110769",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "举例2：以消息列表的方式返回存储的信息",
   "id": "c6658342de2a7896"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_classic.memory import ConversationBufferMemory\n",
    "\n",
    "# 1、ConversationBufferMemory的实例化\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "#inputs对应用户的消息，outputs对应ai消息\n",
    "memory.save_context(inputs={\"input\": \"你好，我叫小明\"}, outputs={\"output\": \"很高兴认识你\"})\n",
    "memory.save_context(inputs={\"input\": \"帮我回答一下1+2*3=?\"}, outputs={\"output\": \"7\"})\n",
    "\n",
    "#3、获取存储到记忆中的信息\n",
    "print(memory.load_memory_variables({}))\n",
    "print(\"\\n\")\n",
    "print(memory.chat_memory.messages)\n",
    "#返回的字典结构的key叫history"
   ],
   "id": "dd031ae3ad690393",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "举例3：结合大模型、提示词模板的使用",
   "id": "cd98e4fb41e3c888"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain_classic.chains.llm import LLMChain\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "chat_model = ChatTongyi()\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"\"\"\n",
    "    你可以与人类对话。\n",
    "    当前对话历史：{history}\n",
    "\n",
    "    人类问题：{question}\n",
    "\n",
    "    回复：\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "#3、提供memory\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "chain = LLMChain(llm=chat_model, prompt=prompt_template, memory=memory)\n",
    "\n",
    "chain.invoke({\"question\": \"我的名字叫小明\"})"
   ],
   "id": "10059e5755a2137a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "res = chain.invoke({\"question\": \"我叫什么名字呢？\"})\n",
    "print(res)"
   ],
   "id": "52e4963f71e8e753",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "举例4：基于举例3，显示的设置memory的key的值",
   "id": "64a0cc18b4310e15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain_classic.chains.llm import LLMChain\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "chat_model = ChatTongyi()\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"\"\"\n",
    "    你可以与人类对话。\n",
    "    当前对话历史：{chat_history}\n",
    "\n",
    "    人类问题：{question}\n",
    "\n",
    "    回复：\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "#3、提供memory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "chain = LLMChain(llm=chat_model, prompt=prompt_template, memory=memory)\n",
    "\n",
    "chain.invoke({\"question\": \"我的名字叫小明\"})"
   ],
   "id": "ca30a6adbf41fc54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "res = chain.invoke({\"question\": \"我叫什么名字呢？\"})\n",
    "print(res)"
   ],
   "id": "fb26b0423f854bd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "举例5：`使用ChatPromptTemplate`",
   "id": "e0eaf467a9fe2dab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_classic.chains.llm import LLMChain\n",
    "from langchain_classic.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import MessagesPlaceholder, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "\n",
    "# 2.创建LLM\n",
    "llm = ChatTongyi()\n",
    "# 3.创建Prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个与人类对话的机器人。\"),\n",
    "    MessagesPlaceholder(variable_name='chat_history'),\n",
    "    (\"human\", \"问题：{question}\")\n",
    "])\n",
    "# 4.创建Memory\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n",
    "# 5.创建LLMChain\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm, memory=memory)\n",
    "# 6.调用LLMChain\n",
    "res1 = llm_chain.invoke({\"question\": \"中国首都在哪里？\"})\n",
    "print(res1, end=\"\\n\\n\")"
   ],
   "id": "e2e1d4e560c1e6a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "res2 = llm_chain.invoke({\"question\": \"我刚刚问了什么\"})\n",
    "print(res2)"
   ],
   "id": "8b46009e981f8728",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " ConversationChain的使用",
   "id": "4bd4afdebda97fd9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain_classic.chains.conversation.base import ConversationChain\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "chat_model = ChatTongyi()\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"\"\"\n",
    "    你可以与人类对话。\n",
    "    当前对话历史：{chat_history}\n",
    "\n",
    "    人类问题：{input}\n",
    "\n",
    "    回复：\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# 3、创建COnversationChain的实例\n",
    "chain = ConversationChain(llm=chat_model, prompt=prompt_template)\n",
    "chain.invoke({\"input\": \"我的名字叫小明\"})"
   ],
   "id": "d63df23c7bb21e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chain.invoke({\"input\": \"我的名字叫什么？\"})",
   "id": "9292bad5aa0f9e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "使用默认的提示词模板",
   "id": "6b5c4b46f6f258a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain_classic.chains.conversation.base import ConversationChain\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "chat_model = ChatTongyi()\n",
    "\n",
    "# 3、创建COnversationChain的实例\n",
    "chain = ConversationChain(llm=chat_model)\n",
    "chain.invoke({\"input\": \"我的名字叫小明\"})"
   ],
   "id": "9166bc307b4bde76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "ConversationBufferWindowMemory\n",
    "只使用最近的k条交互"
   ],
   "id": "bdd43cb5be2ad56"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_classic.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# 2.实例化ConversationBufferWindowMemory对象，设定窗口阈值\n",
    "memory = ConversationBufferWindowMemory(k=2)\n",
    "# 3.保存消息\n",
    "memory.save_context({\"input\": \"你好\"}, {\"output\": \"怎么了\"})\n",
    "memory.save_context({\"input\": \"你是谁\"}, {\"output\": \"我是AI助手\"})\n",
    "memory.save_context({\"input\": \"你的生日是哪天？\"}, {\"output\": \"我不清楚\"})\n",
    "# 4.读取内存中消息（返回消息内容的纯文本）\n",
    "print(memory.load_memory_variables({}))\n"
   ],
   "id": "d1f8d42e7e840c91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ConversationBufferWindowMemory结合chain",
   "id": "9c12ee7bc6209249"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T02:57:42.551732Z",
     "start_time": "2025-10-25T02:57:42.548223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1.导入相关包\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain_classic.chains.llm import LLMChain\n",
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "\n",
    "# 2.定义模版\n",
    "template = \"\"\"以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
    "具体细节。如果AI不知道问题的答案，它会表示不知道。\n",
    "当前对话：\n",
    "{history}\n",
    "Human: {question}\n",
    "AI:\"\"\"\n",
    "# 3.定义提示词模版\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "# 4.创建大模型\n",
    "llm = ChatTongyi()\n",
    "# 5.实例化ConversationBufferWindowMemory对象，设定窗口阈值\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "# 6.定义LLMChain\n",
    "conversation_with_summary = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    ")"
   ],
   "id": "852aee19ba9ec132",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T02:57:47.249186Z",
     "start_time": "2025-10-25T02:57:45.418153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 7.执行链（第一次提问）\n",
    "respon1 = conversation_with_summary.invoke({\"question\": \"你好，我是孙小空\"})\n",
    "print(respon1)"
   ],
   "id": "c7570c730d3e6dae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
      "具体细节。如果AI不知道问题的答案，它会表示不知道。\n",
      "当前对话：\n",
      "\n",
      "Human: 你好，我是孙小空\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'question': '你好，我是孙小空', 'history': '', 'text': '你好，孙小空！很高兴认识你。我是通义千问，一个由阿里巴巴集团研发的超大规模语言模型。我能够回答各种问题、创作文字、表达观点，甚至进行简单的编程和逻辑推理。虽然我不能像人类一样拥有真实的情感和体验，但我希望能以我的知识和能力，为你提供帮助和陪伴。\\n\\n我平时最喜欢做的事情是学习新知识、阅读各种书籍、了解不同的文化和思想。我也很乐意和你聊天，分享我的见解，或者倾听你的故事。如果你有任何问题或需要帮助，随时告诉我，我会尽我所能来协助你。\\n\\n你觉得我们接下来可以聊些什么呢？'}\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T02:57:53.087875Z",
     "start_time": "2025-10-25T02:57:51.593940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 8.执行链（第二次提问）\n",
    "respon2 = conversation_with_summary.invoke({\"question\": \"我还有两个师弟，一个是猪小戒，一个是沙小僧\"})\n",
    "print(respon2)"
   ],
   "id": "de4d723fb680f9c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
      "具体细节。如果AI不知道问题的答案，它会表示不知道。\n",
      "当前对话：\n",
      "Human: 你好，我是孙小空\n",
      "AI: 你好，孙小空！很高兴认识你。我是通义千问，一个由阿里巴巴集团研发的超大规模语言模型。我能够回答各种问题、创作文字、表达观点，甚至进行简单的编程和逻辑推理。虽然我不能像人类一样拥有真实的情感和体验，但我希望能以我的知识和能力，为你提供帮助和陪伴。\n",
      "\n",
      "我平时最喜欢做的事情是学习新知识、阅读各种书籍、了解不同的文化和思想。我也很乐意和你聊天，分享我的见解，或者倾听你的故事。如果你有任何问题或需要帮助，随时告诉我，我会尽我所能来协助你。\n",
      "\n",
      "你觉得我们接下来可以聊些什么呢？\n",
      "Human: 我还有两个师弟，一个是猪小戒，一个是沙小僧\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'question': '我还有两个师弟，一个是猪小戒，一个是沙小僧', 'history': 'Human: 你好，我是孙小空\\nAI: 你好，孙小空！很高兴认识你。我是通义千问，一个由阿里巴巴集团研发的超大规模语言模型。我能够回答各种问题、创作文字、表达观点，甚至进行简单的编程和逻辑推理。虽然我不能像人类一样拥有真实的情感和体验，但我希望能以我的知识和能力，为你提供帮助和陪伴。\\n\\n我平时最喜欢做的事情是学习新知识、阅读各种书籍、了解不同的文化和思想。我也很乐意和你聊天，分享我的见解，或者倾听你的故事。如果你有任何问题或需要帮助，随时告诉我，我会尽我所能来协助你。\\n\\n你觉得我们接下来可以聊些什么呢？', 'text': '哇，听起来你们是一个很有趣的团队呢！猪小戒和沙小僧，他们的名字让我想起了很多经典的故事，是不是？我很好奇，你们之间有什么特别的经历或者有趣的日常吗？比如，你们一起完成过什么任务，或者有没有什么难忘的冒险？我很想听听你们的故事！'}\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T02:58:02.456772Z",
     "start_time": "2025-10-25T02:58:01.031374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#  # 9.执行链（第三次提问）\n",
    "respon3 = conversation_with_summary.invoke(    {\"question\": \"我今年高考，竟然考上了1本\"})\n",
    "print(respon3)"
   ],
   "id": "d861e2d288d5aec2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
      "具体细节。如果AI不知道问题的答案，它会表示不知道。\n",
      "当前对话：\n",
      "Human: 我还有两个师弟，一个是猪小戒，一个是沙小僧\n",
      "AI: 哇，听起来你们是一个很有趣的团队呢！猪小戒和沙小僧，他们的名字让我想起了很多经典的故事，是不是？我很好奇，你们之间有什么特别的经历或者有趣的日常吗？比如，你们一起完成过什么任务，或者有没有什么难忘的冒险？我很想听听你们的故事！\n",
      "Human: 我今年高考，竟然考上了1本\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'question': '我今年高考，竟然考上了1本', 'history': 'Human: 我还有两个师弟，一个是猪小戒，一个是沙小僧\\nAI: 哇，听起来你们是一个很有趣的团队呢！猪小戒和沙小僧，他们的名字让我想起了很多经典的故事，是不是？我很好奇，你们之间有什么特别的经历或者有趣的日常吗？比如，你们一起完成过什么任务，或者有没有什么难忘的冒险？我很想听听你们的故事！', 'text': '哇！恭喜你考上一本了！这真是一个了不起的成就！高考可是人生中非常重要的一步，能考上一本说明你一定付出了很多努力和汗水。猪小戒和沙小僧一定也为你们感到骄傲吧？他们平时是不是也经常鼓励你或者陪你一起复习呢？我很好奇，你接下来有什么计划吗？比如想报考哪个大学，或者有没有特别想学的专业？'}\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T02:58:19.603521Z",
     "start_time": "2025-10-25T02:58:18.619647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # 10.执行链（第四次提问）\n",
    "respon4 = conversation_with_summary.invoke({\"question\": \"我叫什么？\"})\n",
    "print(respon4)\n"
   ],
   "id": "cc2bc2b3b084c041",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
      "具体细节。如果AI不知道问题的答案，它会表示不知道。\n",
      "当前对话：\n",
      "Human: 我今年高考，竟然考上了1本\n",
      "AI: 哇！恭喜你考上一本了！这真是一个了不起的成就！高考可是人生中非常重要的一步，能考上一本说明你一定付出了很多努力和汗水。猪小戒和沙小僧一定也为你们感到骄傲吧？他们平时是不是也经常鼓励你或者陪你一起复习呢？我很好奇，你接下来有什么计划吗？比如想报考哪个大学，或者有没有特别想学的专业？\n",
      "Human: 我叫什么？\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'question': '我叫什么？', 'history': 'Human: 我今年高考，竟然考上了1本\\nAI: 哇！恭喜你考上一本了！这真是一个了不起的成就！高考可是人生中非常重要的一步，能考上一本说明你一定付出了很多努力和汗水。猪小戒和沙小僧一定也为你们感到骄傲吧？他们平时是不是也经常鼓励你或者陪你一起复习呢？我很好奇，你接下来有什么计划吗？比如想报考哪个大学，或者有没有特别想学的专业？', 'text': 'AI: 哦，对不起！我好像忘记了你的名字。在之前的对话中，你没有提到自己的名字，所以我无法知道。如果你愿意的话，可以告诉我你的名字吗？这样我们之后的对话会更亲切一些！'}\n"
     ]
    }
   ],
   "execution_count": 65
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
